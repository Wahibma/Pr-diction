import pandas as pd
import numpy as np
import streamlit as st
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from joblib import dump, load
import difflib
import matplotlib.pyplot as plt
import seaborn as sns

# Fonction pour charger et pr√©parer les donn√©es
def load_data(filepath):
    donnees = pd.read_csv(filepath, sep=';', encoding='iso-8859-1')
    donnees['Date d√©p√¥t GED'] = pd.to_datetime(donnees['Date d√©p√¥t GED'], format='%d/%m/%Y', errors='coerce')
    donnees['Nombre d\'indices'] = donnees.groupby(['TYPE DE DOCUMENT', 'Categ_Docs', 'desc_lot', 'Libell√© du document'])['INDICE'].transform('nunique')
    donnees = donnees[['TYPE DE DOCUMENT', 'Categ_Docs', 'desc_lot', 'Nombre d\'indices']]
    
    encoder = OneHotEncoder(handle_unknown='ignore')
    encoded_vars = encoder.fit_transform(donnees[['TYPE DE DOCUMENT', 'Categ_Docs', 'desc_lot']]).toarray()
    encoded_vars_df = pd.DataFrame(encoded_vars, columns=encoder.get_feature_names_out())
    
    df_final = pd.concat([encoded_vars_df, donnees[['Nombre d\'indices']]], axis=1)
    
    X = df_final.drop(columns=['Nombre d\'indices'])
    y = df_final['Nombre d\'indices']
    
    return train_test_split(X, y, test_size=0.2, random_state=42), encoder, donnees

# Fonction pour entra√Æner et √©valuer les mod√®les
def train_and_evaluate_models(X_train, X_test, y_train, y_test):
    results = {}
    
    # R√©gression lin√©aire
    model_lr = LinearRegression()
    model_lr.fit(X_train, y_train)
    y_pred_lr = model_lr.predict(X_test)
    results['R√©gression Lin√©aire'] = {
        'MAE': mean_absolute_error(y_test, y_pred_lr),
        'MSE': mean_squared_error(y_test, y_pred_lr),
        'R2': r2_score(y_test, y_pred_lr)
    }
    
    # For√™t Al√©atoire
    rf_model = RandomForestRegressor(random_state=42)
    rf_model.fit(X_train, y_train)
    y_pred_rf = rf_model.predict(X_test)
    results['For√™t Al√©atoire'] = {
        'MAE': mean_absolute_error(y_test, y_pred_rf),
        'MSE': mean_squared_error(y_test, y_pred_rf),
        'R2': r2_score(y_test, y_pred_rf)
    }
    
    # Gradient Boosting
    gb_model = GradientBoostingRegressor(random_state=42)
    gb_model.fit(X_train, y_train)
    y_pred_gb = gb_model.predict(X_test)
    results['Gradient Boosting'] = {
        'MAE': mean_absolute_error(y_test, y_pred_gb),
        'MSE': mean_squared_error(y_test, y_pred_gb),
        'R2': r2_score(y_test, y_pred_gb)
    }
    
    return results, model_lr, rf_model, gb_model

# Fonction pour s√©lectionner le meilleur mod√®le
def select_best_model(results):
    best_model_name = min(results, key=lambda x: results[x]['MAE'])
    return best_model_name

# Fonction pour trouver des suggestions pour des cat√©gories inconnues
def find_similar_category(category, category_list):
    similar = difflib.get_close_matches(category, category_list)
    return similar

# Charger les donn√©es et l'encodeur
(X_train, X_test, y_train, y_test), encoder, donnees = load_data('GOODLIFE_pr√©.csv')

# Entra√Æner et √©valuer les mod√®les
results, model_lr, rf_model, gb_model = train_and_evaluate_models(X_train, X_test, y_train, y_test)

# S√©lectionner le meilleur mod√®le
best_model_name = select_best_model(results)
best_model = {'R√©gression Lin√©aire': model_lr, 'For√™t Al√©atoire': rf_model, 'Gradient Boosting': gb_model}[best_model_name]

# Enregistrer le meilleur mod√®le
dump(best_model, 'best_model.joblib')
dump(encoder, 'encoder.joblib')

# D√©finir la configuration de la page
st.set_page_config(page_title="Pr√©diction du Nombre Moyen d'Indices", layout="wide")

# Titre de l'application
st.title('üîç Outil de Pr√©diction du Nombre Moyen d\'Indices')

# Description de l'application
st.write("""
### Description
Cet outil de pr√©diction utilise des techniques de machine learning pour estimer le nombre moyen d'indices en fonction de diff√©rents types de documents, cat√©gories de documents et descriptions de lots. 
Il s'agit d'un outil puissant et facile √† utiliser pour obtenir des pr√©dictions pr√©cises.
""")

# Structurer la mise en page avec des colonnes
col1, col2 = st.columns(2)

with col1:
    st.header("R√©sultats des Mod√®les")
    st.write("Les r√©sultats des diff√©rents mod√®les de machine learning utilis√©s pour la pr√©diction :")
    results_df = pd.DataFrame(results).T
    st.write(results_df)
    st.write(f"**Le Meilleur Mod√®le est : {best_model_name}**")
    st.write("""
    ### Explication des Mod√®les
    - **R√©gression Lin√©aire** : Ce mod√®le est simple et rapide √† ex√©cuter. Il est utile pour comprendre la relation lin√©aire entre les variables ind√©pendantes et la variable d√©pendante. Cependant, il peut manquer de pr√©cision pour des relations complexes et non lin√©aires.
    - **For√™t Al√©atoire** : Ce mod√®le est un ensemble d'arbres de d√©cision qui am√©liore la pr√©cision et la robustesse de la pr√©diction. Il est efficace pour capturer les relations non lin√©aires et pour g√©rer les donn√©es avec de nombreuses variables. Cependant, il peut √™tre moins interpr√©table que la r√©gression lin√©aire.
    - **Gradient Boosting** : Ce mod√®le construit des arbres de d√©cision de mani√®re s√©quentielle, chaque arbre corrigant les erreurs des arbres pr√©c√©dents. Il est tr√®s pr√©cis et efficace pour les relations complexes, mais peut √™tre plus difficile √† interpr√©ter et plus long √† entra√Æner.
    """)

with col2:
    st.header("Faites des Pr√©dictions")
    st.write("""
    ### Instructions
    1. **Type de Document** : S√©lectionnez le type de document dans la liste d√©roulante.
    2. **Cat√©gorie de Document** : S√©lectionnez la cat√©gorie de document dans la liste d√©roulante.
    3. **Description du Lot** : S√©lectionnez la description du lot dans la liste d√©roulante.
    4. Cliquez sur le bouton **Pr√©dire** pour obtenir la pr√©diction du nombre moyen d'indices.
    """)

    # Obtenir les valeurs uniques pour les listes d√©roulantes
    known_type_docs = donnees['TYPE DE DOCUMENT'].unique()
    known_categ_docs = donnees['Categ_Docs'].unique()
    known_desc_lot = donnees['desc_lot'].unique()

    type_doc = st.selectbox('Type de Document', known_type_docs, help='S√©lectionnez le type de document.')
    categ_docs = st.selectbox('Cat√©gorie de Document', known_categ_docs, help='S√©lectionnez la cat√©gorie de document.')
    desc_lot = st.selectbox('Description du Lot', known_desc_lot, help='S√©lectionnez la description du lot.')

    if st.button('Pr√©dire'):
        # Encoder les variables d'entr√©e
        input_data = pd.DataFrame([[type_doc, categ_docs, desc_lot]], columns=['TYPE DE DOCUMENT', 'Categ_Docs', 'desc_lot'])

        suggestions = {}

        if type_doc not in known_type_docs:
            suggestions['TYPE DE DOCUMENT'] = find_similar_category(type_doc, known_type_docs)
        if categ_docs not in known_categ_docs:
            suggestions['Categ_Docs'] = find_similar_category(categ_docs, known_categ_docs)
        if desc_lot not in known_desc_lot:
            suggestions['desc_lot'] = find_similar_category(desc_lot, known_desc_lot)

        if suggestions:
            st.error("Cat√©gories inconnues d√©tect√©es. Voici des suggestions :")
            for key, value in suggestions.items():
                st.write(f"{key} : {value}")
        else:
            encoded_vars = encoder.transform(input_data).toarray()

            # Charger le mod√®le
            model = load('best_model.joblib')

            # Pr√©dire
            prediction = model.predict(encoded_vars)
            st.success(f"Nombre moyen d'indices pr√©dit : {prediction[0]}")
            
            # Visualiser les r√©sultats
            st.header("Visualisation des R√©sultats")
            fig, ax = plt.subplots()
            sns.barplot(x=['Prediction'], y=[prediction[0]], ax=ax)
            ax.set_title("Nombre Moyen d'Indices Pr√©dit")
            st.pyplot(fig)

# Ajouter un style personnalis√©
st.markdown("""
<style>
    .reportview-container {
        background: #f0f2f6;
    }
    .sidebar .sidebar-content {
        background: #f0f2f6;
    }
    .stButton>button {
        background-color: #0066cc;
        color: white;
    }
    .stButton>button:hover {
        background-color: #00509e;
    }
</style>
""", unsafe_allow_html=True)
