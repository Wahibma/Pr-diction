import pandas as pd
import numpy as np
import streamlit as st
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from joblib import dump, load
import difflib
import matplotlib.pyplot as plt
import seaborn as sns

# Fonction pour charger et pr√©parer les donn√©es
def load_data(uploaded_file):
    donnees = pd.read_csv(uploaded_file, sep=';', encoding='iso-8859-1')
    donnees['Date d√©p√¥t GED'] = pd.to_datetime(donnees['Date d√©p√¥t GED'], format='%d/%m/%Y', errors='coerce')
    donnees['Nombre d\'indices'] = donnees.groupby(['TYPE DE DOCUMENT', 'Categ_Docs', 'desc_lot', 'Libell√© du document'])['INDICE'].transform('nunique')
    donnees = donnees[['TYPE DE DOCUMENT', 'Categ_Docs', 'desc_lot', 'Nombre d\'indices']]
    
    encoder = OneHotEncoder(handle_unknown='ignore')
    encoded_vars = encoder.fit_transform(donnees[['TYPE DE DOCUMENT', 'Categ_Docs', 'desc_lot']]).toarray()
    encoded_vars_df = pd.DataFrame(encoded_vars, columns=encoder.get_feature_names_out())
    
    df_final = pd.concat([encoded_vars_df, donnees[['Nombre d\'indices']]], axis=1)
    
    X = df_final.drop(columns=['Nombre d\'indices'])
    y = df_final['Nombre d\'indices']
    
    return train_test_split(X, y, test_size=0.2, random_state=42), encoder, donnees

# Fonction pour entra√Æner et √©valuer les mod√®les avec GridSearchCV
def train_and_evaluate_models(X_train, X_test, y_train, y_test):
    results = {}
    models = {}
    
    # R√©gression lin√©aire
    model_lr = LinearRegression()
    model_lr.fit(X_train, y_train)
    y_pred_lr = model_lr.predict(X_test)
    results['R√©gression Lin√©aire'] = {
        'MAE': mean_absolute_error(y_test, y_pred_lr),
        'MSE': mean_squared_error(y_test, y_pred_lr),
        'R2': r2_score(y_test, y_pred_lr)
    }
    models['R√©gression Lin√©aire'] = (model_lr, y_pred_lr)
    
    # For√™t Al√©atoire avec GridSearchCV (r√©duire le nombre de param√®tres)
    rf_model = RandomForestRegressor(random_state=42)
    rf_param_grid = {
        'n_estimators': [100, 200],
        'max_features': ['auto'],
        'max_depth': [10, 20],
        'min_samples_split': [2],
        'min_samples_leaf': [1]
    }
    rf_grid_search = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=3, n_jobs=-1, verbose=1)
    rf_grid_search.fit(X_train, y_train)
    best_rf_model = rf_grid_search.best_estimator_
    y_pred_rf = best_rf_model.predict(X_test)
    results['For√™t Al√©atoire'] = {
        'MAE': mean_absolute_error(y_test, y_pred_rf),
        'MSE': mean_squared_error(y_test, y_pred_rf),
        'R2': r2_score(y_test, y_pred_rf)
    }
    models['For√™t Al√©atoire'] = (best_rf_model, y_pred_rf)
    
    # Gradient Boosting avec GridSearchCV (r√©duire le nombre de param√®tres)
    gb_model = GradientBoostingRegressor(random_state=42)
    gb_param_grid = {
        'n_estimators': [100, 200],
        'learning_rate': [0.1],
        'max_depth': [3, 4],
        'min_samples_split': [2],
        'min_samples_leaf': [1]
    }
    gb_grid_search = GridSearchCV(estimator=gb_model, param_grid=gb_param_grid, cv=3, n_jobs=-1, verbose=1)
    gb_grid_search.fit(X_train, y_train)
    best_gb_model = gb_grid_search.best_estimator_
    y_pred_gb = best_gb_model.predict(X_test)
    results['Gradient Boosting'] = {
        'MAE': mean_absolute_error(y_test, y_pred_gb),
        'MSE': mean_squared_error(y_test, y_pred_gb),
        'R2': r2_score(y_test, y_pred_gb)
    }
    models['Gradient Boosting'] = (best_gb_model, y_pred_gb)
    
    return results, models

# Fonction pour s√©lectionner le meilleur mod√®le
def select_best_model(results):
    best_model_name = min(results, key=lambda x: results[x]['MAE'])
    return best_model_name

# Fonction pour trouver des suggestions pour des cat√©gories inconnues
def find_similar_category(category, category_list):
    similar = difflib.get_close_matches(category, category_list)
    return similar

# D√©finir la configuration de la page
st.set_page_config(page_title="Pr√©diction du Nombre Moyen d'Indices", layout="wide")

# Titre de l'application
st.title('üîç Outil de Pr√©diction du Nombre Moyen d\'Indices')

# Description de l'application
st.write("""
### Description
Cet outil de pr√©diction utilise des techniques de machine learning pour estimer le nombre moyen d'indices en fonction de diff√©rents types de documents, cat√©gories de documents et descriptions de lots. 
Il s'agit d'un outil puissant et facile √† utiliser pour obtenir des pr√©dictions pr√©cises.
""")

# T√©l√©chargement du fichier CSV
uploaded_file = st.file_uploader("Choisissez un fichier CSV", type="csv")

if uploaded_file is not None:
    # Charger les donn√©es et l'encodeur
    (X_train, X_test, y_train, y_test), encoder, donnees = load_data(uploaded_file)

    # Entra√Æner et √©valuer les mod√®les
    results, models = train_and_evaluate_models(X_train, X_test, y_train, y_test)

    # S√©lectionner le meilleur mod√®le
    best_model_name = select_best_model(results)
    best_model, best_model_pred = models[best_model_name]

    # Enregistrer le meilleur mod√®le
    dump(best_model, 'best_model.joblib')
    dump(encoder, 'encoder.joblib')

    col1, col2 = st.columns(2)

    with col1:
        st.header("R√©sultats des Mod√®les")
        st.write("Les r√©sultats des diff√©rents mod√®les de machine learning utilis√©s pour la pr√©diction :")
        results_df = pd.DataFrame(results).T
        st.write(results_df)
        st.write(f"**Le Meilleur Mod√®le est : {best_model_name}**")
        st.write("""
        ### Explication des Mod√®les
        - **R√©gression Lin√©aire** : Ce mod√®le est simple et rapide √† ex√©cuter. Il est utile pour comprendre la relation lin√©aire entre les variables ind√©pendantes et la variable d√©pendante. Cependant, il peut manquer de pr√©cision pour des relations complexes et non lin√©aires.
        - **For√™t Al√©atoire** : Ce mod√®le est un ensemble d'arbres de d√©cision qui am√©liore la pr√©cision et la robustesse de la pr√©diction. Il est efficace pour capturer les relations non lin√©aires et pour g√©rer les donn√©es avec de nombreuses variables. Cependant, il peut √™tre moins interpr√©table que la r√©gression lin√©aire.
        - **Gradient Boosting** : Ce mod√®le construit des arbres de d√©cision de mani√®re s√©quentielle, chaque arbre corrigant les erreurs des arbres pr√©c√©dents. Il est tr√®s pr√©cis et efficace pour les relations complexes, mais peut √™tre plus difficile √† interpr√©ter et plus long √† entra√Æner.
        """)

        # Importance des variables
        st.header("Importance des Variables")
        if best_model_name in ['For√™t Al√©atoire', 'Gradient Boosting']:
            importances = models[best_model_name][0].feature_importances_
            feature_names = encoder.get_feature_names_out()
            importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
            importance_df = importance_df.sort_values(by='Importance', ascending=False)
            st.write(importance_df)
            
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.barplot(x='Importance', y='Feature', data=importance_df, ax=ax)
            ax.set_title(f'Importance des Variables pour le mod√®le {best_model_name}')
            st.pyplot(fig)

    with col2:
        st.header("Faites des Pr√©dictions")
        st.write("""
        ### Instructions
        1. **Type de Document** : S√©lectionnez le type de document dans la liste d√©roulante.
        2. **Cat√©gorie de Document** : S√©lectionnez la cat√©gorie de document dans la liste d√©roulante.
        3. **Description du Lot** : S√©lectionnez la description du lot dans la liste d√©roulante.
        4. Cliquez sur le bouton **Pr√©dire** pour obtenir la pr√©diction du nombre moyen d'indices.
        """)

        # Obtenir les valeurs uniques pour les listes d√©roulantes
        known_type_docs = donnees['TYPE DE DOCUMENT'].unique()
        known_categ_docs = donnees['Categ_Docs'].unique()
        known_desc_lot = donnees['desc_lot'].unique()

        type_doc = st.selectbox('Type de Document', known_type_docs, key='type_doc', help='S√©lectionnez le type de document.')
        categ_docs = st.selectbox('Cat√©gorie de Document', known_categ_docs, key='categ_docs', help='S√©lectionnez la cat√©gorie de document.')
        desc_lot = st.selectbox('Description du Lot', known_desc_lot, key='desc_lot', help='S√©lectionnez la description du lot.')

        if st.button('Pr√©dire'):
            # V√©rification de la coh√©rence des donn√©es
            if type_doc not in known_type_docs:
                st.error(f"Type de Document '{type_doc}' n'est pas reconnu.")
            elif categ_docs not in known_categ_docs:
                st.error(f"Cat√©gorie de Document '{categ_docs}' n'est pas reconnue.")
            elif desc_lot not in known_desc_lot:
                st.error(f"Description du Lot '{desc_lot}' n'est pas reconnue.")
            else:
                # Encoder les variables d'entr√©e
                input_data = pd.DataFrame([[type_doc, categ_docs, desc_lot]], columns=['TYPE DE DOCUMENT', 'Categ_Docs', 'desc_lot'])
                encoded_vars = encoder.transform(input_data).toarray()

                # Charger le mod√®le
                model = load('best_model.joblib')

                # Pr√©dire
                prediction = model.predict(encoded_vars)
                st.success(f"Nombre moyen d'indices pr√©dit : {prediction[0]}")

# Ajouter un style personnalis√©
st.markdown("""
<style>
    .reportview-container {
        background: #f0f2f6;
    }
    .sidebar .sidebar-content {
        background: #f0f2f6;
    }
    .stButton>button {
        background-color: #0066cc;
        color: white;
    }
    .stButton>button:hover {
        background-color: #00509e;
    }
</style>
""", unsafe_allow_html=True)
