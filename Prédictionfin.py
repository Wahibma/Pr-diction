import pandas as pd
import numpy as np
import streamlit as st
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from joblib import dump, load
import difflib
import matplotlib.pyplot as plt
import seaborn as sns

# Fonction pour charger et pr√©parer les donn√©es
def charger_donnees(fichier_telecharge=None):
    if fichier_telecharge is not None:
        donnees = pd.read_csv(fichier_telecharge, sep=';', encoding='iso-8859-1')
    else:
        donnees = pd.read_csv('GOODLIFE_pr√©.csv', sep=';', encoding='iso-8859-1')
        
    donnees['Date d√©p√¥t GED'] = pd.to_datetime(donnees['Date d√©p√¥t GED'], format='%d/%m/%Y', errors='coerce')
    donnees['Nombre d\'indices'] = donnees.groupby(['TYPE DE DOCUMENT', 'Categ_Docs', 'desc_lot', 'Libell√© du document'])['INDICE'].transform('nunique')
    donnees = donnees[['TYPE DE DOCUMENT', 'Categ_Docs', 'desc_lot', 'Nombre d\'indices']]
    
    encodeur = OneHotEncoder(handle_unknown='ignore')
    variables_encodees = encodeur.fit_transform(donnees[['TYPE DE DOCUMENT', 'Categ_Docs', 'desc_lot']]).toarray()
    variables_encodees_df = pd.DataFrame(variables_encodees, columns=encodeur.get_feature_names_out())
    
    df_final = pd.concat([variables_encodees_df, donnees[['Nombre d\'indices']]], axis=1)
    
    X = df_final.drop(columns=['Nombre d\'indices'])
    y = df_final['Nombre d\'indices']
    
    return train_test_split(X, y, test_size=0.2, random_state=42), encodeur, donnees

# Fonction pour entra√Æner et √©valuer les mod√®les avec GridSearchCV
def entrainer_et_evaluer_modeles(X_train, X_test, y_train, y_test):
    resultats = {}
    modeles = {}
    
    # R√©gression lin√©aire
    modele_rl = LinearRegression()
    modele_rl.fit(X_train, y_train)
    y_pred_rl = modele_rl.predict(X_test)
    resultats['R√©gression Lin√©aire'] = {
        'MAE': mean_absolute_error(y_test, y_pred_rl),
        'MSE': mean_squared_error(y_test, y_pred_rl),
        'R2': r2_score(y_test, y_pred_rl)
    }
    modeles['R√©gression Lin√©aire'] = (modele_rl, y_pred_rl)
    
    # For√™t Al√©atoire avec GridSearchCV (r√©duire le nombre de param√®tres)
    modele_fa = RandomForestRegressor(random_state=42)
    grille_param_fa = {
        'n_estimators': [100, 200],
        'max_features': ['auto'],
        'max_depth': [10, 20],
        'min_samples_split': [2],
        'min_samples_leaf': [1]
    }
    recherche_fa = GridSearchCV(estimator=modele_fa, param_grid=grille_param_fa, cv=3, n_jobs=-1, verbose=1)
    recherche_fa.fit(X_train, y_train)
    meilleur_modele_fa = recherche_fa.best_estimator_
    y_pred_fa = meilleur_modele_fa.predict(X_test)
    resultats['For√™t Al√©atoire'] = {
        'MAE': mean_absolute_error(y_test, y_pred_fa),
        'MSE': mean_squared_error(y_test, y_pred_fa),
        'R2': r2_score(y_test, y_pred_fa)
    }
    modeles['For√™t Al√©atoire'] = (meilleur_modele_fa, y_pred_fa)
    
    # Gradient Boosting avec GridSearchCV (r√©duire le nombre de param√®tres)
    modele_gb = GradientBoostingRegressor(random_state=42)
    grille_param_gb = {
        'n_estimators': [100, 200],
        'learning_rate': [0.1],
        'max_depth': [3, 4],
        'min_samples_split': [2],
        'min_samples_leaf': [1]
    }
    recherche_gb = GridSearchCV(estimator=modele_gb, param_grid=grille_param_gb, cv=3, n_jobs=-1, verbose=1)
    recherche_gb.fit(X_train, y_train)
    meilleur_modele_gb = recherche_gb.best_estimator_
    y_pred_gb = meilleur_modele_gb.predict(X_test)
    resultats['Gradient Boosting'] = {
        'MAE': mean_absolute_error(y_test, y_pred_gb),
        'MSE': mean_squared_error(y_test, y_pred_gb),
        'R2': r2_score(y_test, y_pred_gb)
    }
    modeles['Gradient Boosting'] = (meilleur_modele_gb, y_pred_gb)
    
    return resultats, modeles

# Fonction pour s√©lectionner le meilleur mod√®le
def selectionner_meilleur_modele(resultats):
    meilleur_modele_nom = min(resultats, key=lambda x: resultats[x]['MAE'])
    return meilleur_modele_nom

# Fonction pour trouver des suggestions pour des cat√©gories inconnues
def trouver_categorie_similaire(categorie, liste_categories):
    similaire = difflib.get_close_matches(categorie, liste_categories)
    return similaire

# D√©finir la configuration de la page
st.set_page_config(page_title="Pr√©diction du Nombre Moyen d'Indices", layout="wide")

# Titre de l'application
st.title('üîç Outil de Pr√©diction du Nombre Moyen d\'Indices')

# Description de l'application
st.write("""
### Description
Cet outil de pr√©diction utilise des techniques de machine learning pour estimer le nombre moyen d'indices en fonction de diff√©rents types de documents, cat√©gories de documents et descriptions de lots. 
Il s'agit d'un outil puissant et facile √† utiliser pour obtenir des pr√©dictions pr√©cises.
""")

# T√©l√©chargement du fichier CSV
fichier_telecharge = st.file_uploader("Choisissez un fichier CSV", type="csv")

# Charger les donn√©es et l'encodeur
(X_train, X_test, y_train, y_test), encodeur, donnees = charger_donnees(fichier_telecharge)

# Entra√Æner et √©valuer les mod√®les
resultats, modeles = entrainer_et_evaluer_modeles(X_train, X_test, y_train, y_test)

# S√©lectionner le meilleur mod√®le
meilleur_modele_nom = selectionner_meilleur_modele(resultats)
meilleur_modele, meilleur_modele_pred = modeles[meilleur_modele_nom]

# Enregistrer le meilleur mod√®le
dump(meilleur_modele, 'meilleur_modele.joblib')
dump(encodeur, 'encodeur.joblib')

col1, col2 = st.columns(2)

with col1:
    st.header("1. R√©sultats des mod√®les")
    st.write("Les r√©sultats des diff√©rents mod√®les de machine learning utilis√©s pour la pr√©diction :")
    resultats_df = pd.DataFrame(resultats).T
    st.write(resultats_df)
    st.write(f"**Le Meilleur Mod√®le est : {meilleur_modele_nom}**")
    st.write("""
    ### Explication des Mod√®les
    - **R√©gression Lin√©aire** : Ce mod√®le est simple et rapide √† ex√©cuter. Il est utile pour comprendre la relation lin√©aire entre les variables ind√©pendantes et la variable d√©pendante. Cependant, il peut manquer de pr√©cision pour des relations complexes et non lin√©aires.
    - **For√™t Al√©atoire** : Ce mod√®le est un ensemble d'arbres de d√©cision qui am√©liore la pr√©cision et la robustesse de la pr√©diction. Il est efficace pour capturer les relations non lin√©aires et pour g√©rer les donn√©es avec de nombreuses variables. Cependant, il peut √™tre moins interpr√©table que la r√©gression lin√©aire.
    - **Gradient Boosting** : Ce mod√®le construit des arbres de d√©cision de mani√®re s√©quentielle, chaque arbre corrigant les erreurs des arbres pr√©c√©dents. Il est tr√®s pr√©cis et efficace pour les relations complexes, mais peut √™tre plus difficile √† interpr√©ter et plus long √† entra√Æner.
    """)

    # Effet des modalit√©s de chaque variable
    st.header("2. Effet des modalit√©s de chaque variable")
    if meilleur_modele_nom in ['For√™t Al√©atoire', 'Gradient Boosting']:
        importances = modeles[meilleur_modele_nom][0].feature_importances_
        noms_variables = encodeur.get_feature_names_out()
        importance_df = pd.DataFrame({'Variable': noms_variables, 'Importance': importances})
        importance_df = importance_df.sort_values(by='Importance', ascending=False)
        st.write(importance_df)
        
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.barplot(x='Importance', y='Variable', data=importance_df, ax=ax)
        ax.set_title(f'Importance des Variables pour le mod√®le {meilleur_modele_nom}')
        st.pyplot(fig)

with col2:
    st.header("Faites des Pr√©dictions")
    st.write("""
    ### Instructions
    1. **Type de Document** : S√©lectionnez le type de document dans la liste d√©roulante.
    2. **Cat√©gorie de Document** : S√©lectionnez la cat√©gorie de document dans la liste d√©roulante.
    3. **Description du Lot** : S√©lectionnez la description du lot dans la liste d√©roulante.
    4. Cliquez sur le bouton **Pr√©dire** pour obtenir la pr√©diction du nombre moyen d'indices.
    """)

    # Obtenir les valeurs uniques pour les listes d√©roulantes
    types_docs_connus = donnees['TYPE DE DOCUMENT'].unique()
    categories_docs_connues = donnees['Categ_Docs'].unique()
    descriptions_lot_connues = donnees['desc_lot'].unique()

    type_doc = st.selectbox('Type de Document', types_docs_connus, key='type_doc', help='S√©lectionnez le type de document.')
    categ_docs = st.selectbox('Cat√©gorie de Document', categories_docs_connues, key='categ_docs', help='S√©lectionnez la cat√©gorie de document.')
    desc_lot = st.selectbox('Description du Lot', descriptions_lot_connues, key='desc_lot', help='S√©lectionnez la description du lot.')

    if st.button('Pr√©dire'):
        # V√©rification de la coh√©rence des donn√©es
        if type_doc not in types_docs_connus:
            st.error(f"Type de Document '{type_doc}' n'est pas reconnu.")
        elif categ_docs not in categories_docs_connues:
            st.error(f"Cat√©gorie de Document '{categ_docs}' n'est pas reconnue.")
        elif desc_lot not in descriptions_lot_connues:
            st.error(f"Description du Lot '{desc_lot}' n'est pas reconnue.")
        else:
            # Encoder les variables d'entr√©e
            donnees_entree = pd.DataFrame([[type_doc, categ_docs, desc_lot]], columns=['TYPE DE DOCUMENT', 'Categ_Docs', 'desc_lot'])
            variables_encodees = encodeur.transform(donnees_entree).toarray()

            # Charger le mod√®le
            modele = load('meilleur_modele.joblib')

            # Pr√©dire
            prediction = modele.predict(variables_encodees)
            st.success(f"Nombre moyen d'indices pr√©dit : {prediction[0]}")

# Ajouter un style personnalis√©
st.markdown("""
<style>
    .reportview-container {
        background: #f0f2f6;
    }
    .sidebar .sidebar-content {
        background: #f0f2f6;
    }
    .stButton>button {
        background-color: #0066cc;
        color: white;
    }
    .stButton>button:hover {
        background-color: #00509e;
    }
</style>
""", unsafe_allow_html=True)
