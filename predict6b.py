import pandas as pd
import numpy as np
import streamlit as st
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from joblib import dump, load
import difflib
import matplotlib.pyplot as plt
import seaborn as sns

# Fonction pour charger et pr√©parer les donn√©es
def load_data(filepath):
    donnees = pd.read_csv(filepath, sep=';', encoding='iso-8859-1')
    donnees['Date d√©p√¥t GED'] = pd.to_datetime(donnees['Date d√©p√¥t GED'], format='%d/%m/%Y', errors='coerce')
    donnees['Nombre d\'indices'] = donnees.groupby(['TYPE DE DOCUMENT', 'Categ_Docs', 'desc_lot', 'Libell√© du document'])['INDICE'].transform('nunique')
    donnees = donnees[['TYPE DE DOCUMENT', 'Categ_Docs', 'desc_lot', 'Nombre d\'indices']]
    
    encoder = OneHotEncoder(handle_unknown='ignore')
    encoded_vars = encoder.fit_transform(donnees[['TYPE DE DOCUMENT', 'Categ_Docs', 'desc_lot']]).toarray()
    encoded_vars_df = pd.DataFrame(encoded_vars, columns=encoder.get_feature_names_out())
    
    df_final = pd.concat([encoded_vars_df, donnees[['Nombre d\'indices']]], axis=1)
    
    X = df_final.drop(columns=['Nombre d\'indices'])
    y = df_final['Nombre d\'indices']
    
    return train_test_split(X, y, test_size=0.2, random_state=42), encoder, donnees

# Fonction pour entra√Æner et √©valuer les mod√®les avec GridSearchCV
def train_and_evaluate_models(X_train, X_test, y_train, y_test):
    results = {}
    models = {}
    
    # R√©gression lin√©aire
    model_lr = LinearRegression()
    model_lr.fit(X_train, y_train)
    y_pred_lr = model_lr.predict(X_test)
    results['R√©gression Lin√©aire'] = {
        'MAE': mean_absolute_error(y_test, y_pred_lr),
        'MSE': mean_squared_error(y_test, y_pred_lr),
        'R2': r2_score(y_test, y_pred_lr)
    }
    models['R√©gression Lin√©aire'] = (model_lr, y_pred_lr)
    
    # For√™t Al√©atoire avec GridSearchCV (r√©duire le nombre de param√®tres)
    rf_model = RandomForestRegressor(random_state=42)
    rf_param_grid = {
        'n_estimators': [100, 200],
        'max_features': ['auto'],
        'max_depth': [10, 20],
        'min_samples_split': [2],
        'min_samples_leaf': [1]
    }
    rf_grid_search = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=3, n_jobs=-1, verbose=1)
    rf_grid_search.fit(X_train, y_train)
    best_rf_model = rf_grid_search.best_estimator_
    y_pred_rf = best_rf_model.predict(X_test)
    results['For√™t Al√©atoire'] = {
        'MAE': mean_absolute_error(y_test, y_pred_rf),
        'MSE': mean_squared_error(y_test, y_pred_rf),
        'R2': r2_score(y_test, y_pred_rf)
    }
    models['For√™t Al√©atoire'] = (best_rf_model, y_pred_rf)
    
    # Gradient Boosting avec GridSearchCV (r√©duire le nombre de param√®tres)
    gb_model = GradientBoostingRegressor(random_state=42)
    gb_param_grid = {
        'n_estimators': [100, 200],
        'learning_rate': [0.1],
        'max_depth': [3, 4],
        'min_samples_split': [2],
        'min_samples_leaf': [1]
    }
    gb_grid_search = GridSearchCV(estimator=gb_model, param_grid=gb_param_grid, cv=3, n_jobs=-1, verbose=1)
    gb_grid_search.fit(X_train, y_train)
    best_gb_model = gb_grid_search.best_estimator_
    y_pred_gb = best_gb_model.predict(X_test)
    results['Gradient Boosting'] = {
        'MAE': mean_absolute_error(y_test, y_pred_gb),
        'MSE': mean_squared_error(y_test, y_pred_gb),
        'R2': r2_score(y_test, y_pred_gb)
    }
    models['Gradient Boosting'] = (best_gb_model, y_pred_gb)
    
    return results, models

# Fonction pour s√©lectionner le meilleur mod√®le
def select_best_model(results):
    best_model_name = min(results, key=lambda x: results[x]['MAE'])
    return best_model_name

# Fonction pour trouver des suggestions pour des cat√©gories inconnues
def find_similar_category(category, category_list):
    similar = difflib.get_close_matches(category, category_list)
    return similar

# Charger les donn√©es et l'encodeur
(X_train, X_test, y_train, y_test), encoder, donnees = load_data('/mnt/data/GOODLIFE_pr√©.csv')

# Entra√Æner et √©valuer les mod√®les
results, models = train_and_evaluate_models(X_train, X_test, y_train, y_test)

# S√©lectionner le meilleur mod√®le
best_model_name = select_best_model(results)
best_model, best_model_pred = models[best_model_name]

# Enregistrer le meilleur mod√®le
dump(best_model, 'best_model.joblib')
dump(encoder, 'encoder.joblib')

# D√©finir la configuration de la page
st.set_page_config(page_title="Pr√©diction du Nombre Moyen d'Indices", layout="wide")

# Titre de l'application
st.title('üîç Outil de Pr√©diction du Nombre Moyen d\'Indices')

# Description de l'application
st.write("""
### Description
Cet outil de pr√©diction utilise des techniques de machine learning pour estimer le nombre moyen d'indices en fonction de diff√©rents types de documents, cat√©gories de documents et descriptions de lots. 
Il s'agit d'un outil puissant et facile √† utiliser pour obtenir des pr√©dictions pr√©cises.
""")

# Structurer la mise en page avec des colonnes
col1, col2 = st.columns(2)

with col1:
    st.header("R√©sultats des Mod√®les")
    st.write("Les r√©sultats des diff√©rents mod√®les de machine learning utilis√©s pour la pr√©diction :")
    results_df = pd.DataFrame(results).T
    st.write(results_df)
    st.write(f"**Le Meilleur Mod√®le est : {best_model_name}**")
    st.write("""
    ### Explication des Mod√®les
    - **R√©gression Lin√©aire** : Ce mod√®le est simple et rapide √† ex√©cuter. Il est utile pour comprendre la relation lin√©aire entre les variables ind√©pendantes et la variable d√©pendante. Cependant, il peut manquer de pr√©cision pour des relations complexes et non lin√©aires.
    - **For√™t Al√©atoire** : Ce mod√®le est un ensemble d'arbres de d√©cision qui am√©liore la pr√©cision et la robustesse de la pr√©diction. Il est efficace pour capturer les relations non lin√©aires et pour g√©rer les donn√©es avec de nombreuses variables. Cependant, il peut √™tre moins interpr√©table que la r√©gression lin√©aire.
    - **Gradient Boosting** : Ce mod√®le construit des arbres de d√©cision de mani√®re s√©quentielle, chaque arbre corrigant les erreurs des arbres pr√©c√©dents. Il est tr√®s pr√©cis et efficace pour les relations complexes, mais peut √™tre plus difficile √† interpr√©ter et plus long √† entra√Æner.
    """)

    # Visualiser les r√©sultats des mod√®les
    st.header("Visualisation des R√©sultats des Mod√®les")
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.plot(y_test.values, label='True Values', marker='o', linestyle='None', alpha=0.6)
    ax.plot(models['R√©gression Lin√©aire'][1], label='R√©gression Lin√©aire', marker='x', linestyle='None', alpha=0.6)
    ax.plot(models['For√™t Al√©atoire'][1], label='For√™t Al√©atoire', marker='s', linestyle='None', alpha=0.6)
    ax.plot(models['Gradient Boosting'][1], label='Gradient Boosting', marker='d', linestyle='None', alpha=0.6)
    ax.legend()
    ax.set_title("Comparaison des Pr√©dictions des Mod√®les")
    st.pyplot(fig)

with col2:
    st.header("Faites des Pr√©dictions")
    st.write("""
    ### Instructions
    1. **Type de Document** : S√©lectionnez le type de document dans la liste d√©roulante.
    2. **Cat√©gorie de Document** : S√©lectionnez la cat√©gorie de document dans la liste d√©roulante.
    3. **Description du Lot** : S√©lectionnez la description du lot dans la liste d√©roulante.
    4. Cliquez sur le bouton **Pr√©dire** pour obtenir la pr√©diction du nombre moyen d'indices.
    """)

    # Obtenir les valeurs uniques pour les listes d√©roulantes
    known_type_docs = donnees['TYPE DE DOCUMENT'].unique()
    known_categ_docs = donnees['Categ_Docs'].unique()
    known_desc_lot = donnees['desc_lot'].unique()

    type_doc = st.selectbox('Type de Document', known_type_docs, key='type_doc', help='S√©lectionnez le type de document.')
    categ_docs = st.selectbox('Cat√©gorie de Document', known_categ_docs, key='categ_docs', help='S√©lectionnez la cat√©gorie de document.')
    desc_lot = st.selectbox('Description du Lot', known_desc_lot, key='desc_lot', help='S√©lectionnez la description du lot.')

    if st.button('Pr√©dire'):
        # Encoder les variables d'entr√©e
        input_data = pd.DataFrame([[type_doc, categ_docs, desc_lot]], columns=['TYPE DE DOCUMENT', 'Categ_Docs', 'desc_lot'])

        suggestions = {}

        if type_doc not in known_type_docs:
            suggestions['TYPE DE DOCUMENT'] = find_similar_category(type_doc, known_type_docs)
        if categ_docs not in known_categ_docs:
            suggestions['Categ_Docs'] = find_similar_category(categ_docs, known_categ_docs)
        if desc_lot not in known_desc_lot:
            suggestions['desc_lot'] = find_similar_category(desc_lot, known_desc_lot)

        if suggestions:
            st.error("Cat√©gories inconnues d√©tect√©es. Voici des suggestions :")
            for key, value in suggestions.items():
                st.write(f"{key} : {value}")
        else:
            encoded_vars = encoder.transform(input_data).toarray()

            # Charger le mod√®le
            model = load('best_model.joblib')

            # Pr√©dire
            prediction = model.predict(encoded_vars)
            st.success(f"Nombre moyen d'indices pr√©dit : {prediction[0]}")
            
            # Visualiser les r√©sultats
            st.header("Visualisation des R√©sultats")
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.barplot(x=['Prediction'], y=[prediction[0]], ax=ax)
            ax.set_title("Nombre Moyen d'Indices Pr√©dit")
            st.pyplot(fig)

# Ajouter un style personnalis√©
st.markdown("""
<style>
    .reportview-container {
        background: #f0f2f6;
    }
    .sidebar .sidebar-content {
        background: #f0f2f6;
    }
    .stButton>button {
        background-color: #0066cc;
        color: white;
    }
    .stButton>button:hover {
        background-color: #00509e;
    }
</style>
""", unsafe_allow_html=True)
